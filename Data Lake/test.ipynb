{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, monotonically_increasing_id #I took out udf\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType, StringType, IntegerType, TimestampType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "os.environ['AWS_ACCESS_KEY_ID']=''\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_spark_session():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# get filepath to song data file\n",
    "song_data = 's3a://udacity-dend/song_data/A/A/*/*.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "song_schema = StructType([\n",
    "                        StructField(\"num_songs\", IntegerType()),\n",
    "                        StructField(\"artist_id\", StringType()),\n",
    "                        StructField(\"artist_latitude\", DoubleType()),\n",
    "                        StructField(\"artist_longitude\", DoubleType()),\n",
    "                        StructField(\"artist_location\", StringType()),\n",
    "                        StructField(\"artist_name\", StringType()),\n",
    "                        StructField(\"song_id\", StringType()),\n",
    "                        StructField(\"title\", StringType()),\n",
    "                        StructField(\"duration\", DoubleType()),\n",
    "                        StructField(\"year\", IntegerType())\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = create_spark_session()\n",
    "\n",
    "df = spark.read.json(song_data, schema=song_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.printSchema()\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"songs_view\")\n",
    "\n",
    "songs_table = spark.sql(\"\"\"\n",
    "                        SELECT song_id, title, artist_id, year, duration\n",
    "                        FROM songs_view\n",
    "                        WHERE song_id IS NOT NULL\n",
    "                        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(type(songs_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "songs_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "songs_table.write.partitionBy(\"year\", \"artist_id\").mode('overwrite').parquet(\"songs.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# extract columns to create artists table\n",
    "artists_table = spark.sql(\"\"\"\n",
    "                          SELECT DISTINCT artist_id, artist_name AS name, artist_location AS location, artist_latitude AS latitude, artist_longitude AS longitude\n",
    "                          FROM songs_view\n",
    "                          WHERE artist_id IS NOT NULL\n",
    "                          \"\"\")\n",
    "artists_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "artists_table.write.mode('overwrite').parquet(\"artists.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "log_data = 's3a://udacity-dend/log_data/*/*/*.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "log_schema = StructType([\n",
    "                        StructField(\"artist\", StringType()),\n",
    "                        StructField(\"auth\", StringType()),\n",
    "                        StructField(\"firstName\", StringType()),\n",
    "                        StructField(\"gender\", StringType()),\n",
    "                        StructField(\"itemInSession\", IntegerType()),\n",
    "                        StructField(\"lastName\", StringType()),\n",
    "                        StructField(\"length\", DoubleType()),\n",
    "                        StructField(\"level\", StringType()),\n",
    "                        StructField(\"location\", StringType()),\n",
    "                        StructField(\"method\", StringType()),\n",
    "                        StructField(\"page\", StringType()),\n",
    "                        StructField(\"registration\", DoubleType()),\n",
    "                        StructField(\"sessionId\", IntegerType()),\n",
    "                        StructField(\"song\", StringType()),\n",
    "                        StructField(\"status\", IntegerType()),\n",
    "                        StructField(\"ts\", IntegerType()),\n",
    "                        StructField(\"userAgent\", StringType()),\n",
    "                        StructField(\"userId\", IntegerType())\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# read log data file\n",
    "###\n",
    "# I CHANGED DF TO DF_LOG, MAKE SURE YOU KNOW THAT THIS WAS CHANGED SO IF YOU KEEP YOU CAN CHANGE ETL.PY\n",
    "df_log = spark.read.json(log_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# filter by actions for song plays\n",
    "df_log = df_log.filter(df_log.page=='NextSong')\n",
    "df_log.createOrReplaceTempView(\"log_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_log.show(10)\n",
    "df_log.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "users_table = spark.sql(\"\"\"\n",
    "                        SELECT DISTINCT userId AS user_id, firstName AS first_name, lastName AS last_name, gender, level\n",
    "                        FROM log_view\n",
    "                        WHERE userId IS NOT NULL\n",
    "                        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "users_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "users_table.write.mode('overwrite').parquet(\"users.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_unixtime\n",
    "\n",
    "# create timestamp column from original timestamp column\n",
    "# get_timestamp = udf(lambda x: (x / 1000))\n",
    "# df_log = df_log.withColumn(\"timestamp\", get_timestamp(df_log.ts))\n",
    "\n",
    "print('Here is the type of ts col:')\n",
    "print(type(df_log.first()['ts']))\n",
    "\n",
    "print('\\n Here is the first value of the ts col:')\n",
    "print((df_log.first()['ts']))\n",
    "\n",
    "# df_log = df_log.withColumn('nonMilli', get_timestamp(df_log.ts))\n",
    "\n",
    "# print('Here is the type of nonMilli col:')\n",
    "# print(type(df_log.first()['nonMilli']))\n",
    "\n",
    "# print('\\n Here is the first value of the nonMilli col:')\n",
    "# print((df_log.first()['nonMilli']))\n",
    "\n",
    "# df_log = df_log.withColumn(\"timestamp5\", from_unixtime(get_timestamp(df_log.ts)))\n",
    "\n",
    "# df_log = df_log.withColumn(\"timestamp4\", get_timestamp(df_log.ts))\n",
    "\n",
    "# df.withColumn(\"tsDate\", from_unixtime($\"timestamp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# df_log = df_log.withColumn('nonMilli', ((df_log.ts)/1000).cast(\"int\").cast(TimestampType()))\n",
    "\n",
    "# print('Here is the type of nonMilli col:')\n",
    "# print(type(df_log.first()['nonMilli']))\n",
    "\n",
    "# print('\\n Here is the first value of the nonMilli col:')\n",
    "# print((df_log.first()['nonMilli']))\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "\n",
    "get_timestamp_no_milliseconds = udf(lambda x: int(int(x)/1000), IntegerType())\n",
    "df_log = df_log.withColumn('timestamp_no_milliseconds', get_timestamp_no_milliseconds(df_log.ts))\n",
    "\n",
    "print('Here is the type of nonMilli col:')\n",
    "print(type(df_log.first()['timestamp_no_milliseconds']))\n",
    "\n",
    "print('\\n Here is the first value of the nonMilli col:')\n",
    "print((df_log.first()['timestamp_no_milliseconds']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# df_log = df_log.withColumn('nonMilli3', col('nonMilli').cast(\"int\"))\n",
    "\n",
    "# print('Here is the nonMilli3 type, should be int:')\n",
    "# print(type(df_log.first()['nonMilli3']))\n",
    "\n",
    "# print('\\n Here is the first value of nonMilli3:')\n",
    "# print(df_log.first()['nonMilli3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "get_datetime = udf(lambda x: datetime.fromtimestamp(x), TimestampType())\n",
    "\n",
    "df_log = df_log.withColumn('start_time', get_datetime(df_log.timestamp_no_milliseconds))\n",
    "\n",
    "print('Here is the type of start_time col:')\n",
    "print(type(df_log.first()['start_time']))\n",
    "\n",
    "print('\\n Here is the first value of the start_time col:')\n",
    "print((df_log.first()['start_time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# print(type(df_log.first()['timestamp5']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create datetime column from original timestamp column\n",
    "# get_datetime = udf(lambda x: datetime.fromtimestamp(x), TimestampType())\n",
    "# df_log = df_log.withColumn(\"start_time\", df_log.nonMilli)\n",
    "df_log.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_log = df_log.withColumn('year', year(df_log.start_time))\n",
    "df_log = df_log.withColumn('month', month(df_log.start_time))\n",
    "df_log = df_log.withColumn('week', weekofyear(df_log.start_time))\n",
    "df_log = df_log.withColumn('weekday', date_format(df_log.start_time, 'E'))\n",
    "df_log = df_log.withColumn('day', dayofmonth(df_log.start_time))\n",
    "df_log = df_log.withColumn('hour', hour(df_log.start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_log.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_log.createOrReplaceTempView(\"log_view_2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_log.printSchema()\n",
    "# print(df_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "time_table = spark.sql(\"\"\"\n",
    "                       SELECT DISTINCT start_time, hour, day, week, weekday, year, month\n",
    "                       FROM log_view_2\n",
    "                       \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "time_table.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "time_table.write.mode('overwrite').parquet('time.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "song_df = spark.read.json(song_data, schema=song_schema)\n",
    "song_df.createOrReplaceTempView(\"songs_view_2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "songplays_table = spark.sql(\"\"\"\n",
    "                            SELECT monotonically_increasing_id() AS songplay_id, l.start_time AS start_time, l.userId AS user_id,\n",
    "                                   l.level AS level, s.song_id AS song_id, s.artist_id AS artist_id, l.sessionId AS session_id,\n",
    "                                   l.location AS location, l.userAgent AS user_agent, l.year AS year, l.month AS month\n",
    "                            FROM songs_view_2 s\n",
    "                            JOIN log_view_2 l ON s.artist_name = l.artist AND s.title = l.song\n",
    "                            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "songplays_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "songplays_table.write.partitionBy(\"year\", \"month\").mode('overwrite').parquet(\"songplays.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "run etl.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "s3://data-lake-project-delaguila/test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "https://data-lake-project-delaguila.s3.us-west-2.amazonaws.com/test/"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
